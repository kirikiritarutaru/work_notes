# Home Activity Monitoring using Low Resolution Infrared Sensor Array

## 論文について (掲載ジャーナルなど)
- Lili Tao, Timothy Volonakis, Bo Tan, Yanguo Jing, Kevin Chetty, and Melvyn Smith
  - arXiv 2018-11-13の論文
  - 意外と最近

## 概要
- 家の中での行動のモニタリングはスマートホームの入力とか健康管理とかに使えて便利
- 大きな利点があるけど，プライバシーが心配
- じゃあ，低解像度(8x8 pixels)でモニタリングできたらいいんじゃね？
- 7つの行動のモニタリング，87.5%の正解率で検出できた

## 問題設定と解決したこと
- 家の中
- 赤外線を用いて
- 低解像度で
- 人物の行動
- を検出

## 何をどう使ったのか
- 使った赤外線センサはPanasonicの[Grid-EYE® Infrared Array Sensor https://www.mouser.jp/new/panasonic/panasonic-grid-eye-infrared-array-sensors/]
- 低解像度の熱画像で人間の行動を表現するのに有効な，空間的および時間的離散コサイン変換手法を提案
  - 人が写っている画像から背景を引く
  - シーケンスが同じ長さにサンプリング
  - 離散コサイン変換ベースで時間的空間的特徴を各シーケンスから抽出
    - 1.一連の画像に対して1次元離散コサイン変換をかけ，時間的特徴ベクトルを作成
    -   実験では，最初の5個の周波数を使った
    - 2.各画像に対して2次元離散コサイン変換をかけ，空間的特徴ベクトルを作成
    -   8x8の係数マトリックスがアウトプット
    -   画像内の低周波成分が選択される特徴ベクトルを構築
    - 3.上記特徴を使ってSVMで推論

## 主張の有効性の検証方法
  - データセット：Infra-ADL2018
    - 7つの行動：
      - fall, sit still, stand still, sit to stand, stand to sit, walking from left to right, and walking from right to left.
  - 3つのセンサー，被験者8人，各行動10回
  - データセットの目的
  - 通常生活の人間の行動を認識するための低解像度赤外線センサの可用性のテスト
  - プライバシー保護しつつ，ヘルスケアのためにてい低解像度赤外線センサが使えるか試行
  - 提案手法が（特に転倒検知で）高い認識精度をとれることを示すためのデータセット
  - ベースラインのアルゴリズムと比較して，7つの行動のうち３つで大幅に良くなった．
  - ベースラインのアルゴリズムの論文としては以下
    - Use of low-resolution infrared pixel array for passive human motion movement and recognition

## 批評
  -  データ数少なくない？
  -  てか，データセット公開してなくない？
  -  読んでる俺らどうしようもなくない？検証しようがなくない？
  -  特徴抽出手法の妥当性の議論は？
  -  オクルージョンどうするの？
  -  うーん，やってみた感が…

## 次に読むべき論文
 (分野について読み始め)
  - 3D Convolutional Neural network for Home Monitoring using Low Resolution Thermal-sensor Array
    - 同じ著者
    - 手法をCNNにしましたって論文かな？

---
# A Spatio-Temporal Deep Learning Approach For Human Action Recognition in Infrared Videos

## 論文について (掲載ジャーナルなど)
- Anuj K Shah, Ripul Ghosh, Aparna Akula
- Proc. of SPIE Vol. 10751

## 概要
- 屋内環境での人間の行動認識は，事故や損傷を回避する上で超重要
  - 対象のアプリケーションドメイン
    - 独居高齢者，障害を持つ人の行動の監視
    - 単独で孤立した工場で働く人の監視
  - 赤外線センサの動画像の空間的時間的特徴を学習する3D-CNNを構築
  - 3D-CNN
    - (2つの畳み込み層＋1つのmax pool層)x2の6層
    - end-to-end？
  - 894のテストビデオのうち85%の分類精度

## 問題設定と解決したこと
- 身体装着型センサーは嫌われる→画像で→照明の問題とかプライバシーやばくね？→デプス画像やシルエットの検知で
  - このコンテクストだとKinectがよく使われてるやでー
  - でも暗いと無理→なら熱画像ならいけんじゃね？
- フォーカスを当てているのは（独居老人とか障害者の）転倒シーンの検出
  - 屋内と屋外でOK
- 近年画像＋CNNが上手くいってる→熱画像でもやられた
- 行動認識のために空間情報＋時間情報が良さそう

## 何をどう使ったのか
- IRカメラ：[FLIR E60 thermal infrared  camera https://www.ivytools.com/FLIR-E60-Infrared-Thermal-Imaging-Camera-p/flir-e60.htm]
  - Spectral range 7.5 to 13 µm
  - 320 x 240 pixel resolution, Frame Rate - 60 fps,
 - Athermalized manual focus lens, focal length 18 mm
- 3D-CNNで推測
 - 入力→conv-32(ReLU)→conv-32(ReLU)→maxpool(dropout)→conv-64(ReLU)→conv-64(ReLU)→maxpool(dropout)→FC-512(ReLU, dropout)→FC-8→softmax
 - 出力層以外でバッチノーマライゼーション
 - バッチサイズは32
 - 最適化手法はADAM
 - 損失関数はカテゴリカルクロスエントロピー

## 主張の有効性の検証方法
- 自作データセットで検証
- データセットの構成
  - 8つの行動を対象
  - 歩く，立つ，転倒，横たわる，座る，椅子から転倒，転倒から座る姿勢へ，転倒から立ち上がる
- 3つの環境で撮影
   - 学生室，寝室，庭
  - 被験者50人以上
  - データ詳細
    - 訓練用2641つのビデオ
    - テスト用894つのビデオ
    -  各ビデオ0.5秒
    -  FLIRは30FPSで撮影したから15フレーム
- テストデータで検証，各行動のクラスの平均F1-Scoreが0.85

## 批評
- 他の転倒検知手法との比較は？
- ドロップアウトとバッチ正規化抜いたネットワークと比較しただけ？
- テストデータでは上手くいってますよーってだけ？
- うーん，熱画像＋3D-CNNをやってみた！感が…

---

# Action recognition from low-resolution infrared sensor for indoor use: a comparative study between deep learning and classical approaches

## 論文について (掲載ジャーナルなど)
 Félix Polla ; Hélène Laurent ; Bruno Emile
 2019 20th IEEE International Conference on Mobile Data Management (MDM)

## 概要
-  低解像度センサーを用いた屋内環境での行動分析
  -  撮影された人がビデオで特定できないことを保証しながら行動認識を実行できるようにするため
-  既存のカメラによる行動認識では被験者の位置が限定される問題があるよね
-  じゃあ，天井に赤外線センサーとりつければよくね？
-  CoCAPSプロジェクトというのを企業とやってる
  -  そこでシナリオとしてオフィス環境と7つの行動を対象とすることを決めた
  -  後の段階でいろんなセンサーの情報をマージして，人間の行動を特徴付ける
  -  このフレームワークの中で低解像度赤外線センサー作ったんだと
-  提案手法：セグメント化された形状の重心位置の追跡から統計属性に基づく特徴＋分類にはMLP
-  F値83%で認識

## 問題設定と解決したこと
-  64x64ピクセルの赤外線センサーを天井に設置
-  オフィス環境
-  7つの行動を対象
  -  アクションなし，落ち着きなく動く，地面に座る，立つ，椅子に座る，ゆっくり歩く(～1m/s)，早く歩く
  -  落ち着きのないアクションの内訳：電話への応答，オブジェクトの移動，パソコンの操作など
  -  オフィスでよくやる動き
-  データセットは700サンプル（各アクション100サンプル）

## 何をどう使ったのか
- ガウシアンフィルタをかけて平滑化＋閾値処理で明るい領域（現在フレームの人領域）と暗い領域（もともと人がいた場所の領域）を見つける
-  特徴量を計算（6つ）
  -  人の領域（楕円領域）の重心の軌跡（重心の動きのベクトル）
  - 軌跡ベクトルの統計特性（平均，最小，最大，標準偏差）
  -  ビデオのアクティビティ＝　sum（セグメント化された人領域の面積 * 各フレームの重心の移動距離）
-  12の属性（明るい領域と暗い領域の２つ＊6つの特徴）をMLPにいれて分類

## 主張の有効性の検証方法
-  ディープラーニングの手法と比較して，実装簡単だし計算リソースが少ない
  - リアルタイムのアプリケーションにいいだろうと主張
-  古典的手法と2つとディープラーニング手法3つ(3D-CNN, LSTM, 3D-CNN+LSTM)と比較
-  3D-CNNのF値85%で提案手法の方法F値83%だから悪くなくね？と主張

## 批評
-  データ公開してくれー
-  1サンプルの長さは？
-  なんで人がいた領域が暗くなるんだ？センサの特性？
-  明るい領域と暗い領域の特徴を計算しているけど，それただ単に前のフレームの人領域計算すればよくね？

## 次に読むべき論文
 [Computer Vision-Based Descriptive Analytics of Seniors’ Daily Activities for Long-Term Health Monitoring]
  Zelun Luo et al.

## 関連研究
-  HOG特徴量+AdaBoostで行動認識
  -  多数のRGBカメラで撮影だったし，研究室環境にアドホックにルールを作っていったって感じ…あんまり
-  熱画像はノイズが多いからオプティカルフローとか勾配に基づく検出方法だと難しいとのこと
-  既存の行動ごとの身体シルエット作って二次元配列走査
  - 身体の特定の部位（手，足，頭）を認識，組み合わせて動作を認識
  - 複数のカメラから3Dの動きをキャプチャして，スケルトン化
