# Home Activity Monitoring using Low Resolution Infrared Sensor Array

## 論文について (掲載ジャーナルなど)
- Lili Tao, Timothy Volonakis, Bo Tan, Yanguo Jing, Kevin Chetty, and Melvyn Smith
  - arXiv 2018-11-13の論文
  - 意外と最近

## 概要
- 家の中での行動のモニタリングはスマートホームの入力とか健康管理とかに使えて便利
- 大きな利点があるけど，プライバシーが心配
- じゃあ，低解像度(8x8 pixels)でモニタリングできたらいいんじゃね？
- 7つの行動のモニタリング，87.5%の正解率で検出できた

## 問題設定と解決したこと
- 家の中
- 赤外線を用いて
- 低解像度で
- 人物の行動
- を検出

## 何をどう使ったのか
- 使った赤外線センサはPanasonicの[Grid-EYE® Infrared Array Sensor https://www.mouser.jp/new/panasonic/panasonic-grid-eye-infrared-array-sensors/]
- 低解像度の熱画像で人間の行動を表現するのに有効な，空間的および時間的離散コサイン変換手法を提案
  - 人が写っている画像から背景を引く
  - シーケンスが同じ長さにサンプリング
  - 離散コサイン変換ベースで時間的空間的特徴を各シーケンスから抽出
    - 1.一連の画像に対して1次元離散コサイン変換をかけ，時間的特徴ベクトルを作成
      - 実験では，最初の5個の周波数を使った
    - 2.各画像に対して2次元離散コサイン変換をかけ，空間的特徴ベクトルを作成
      - 8x8の係数マトリックスがアウトプット
      - 画像内の低周波成分が選択される特徴ベクトルを構築
    - 3.上記特徴を使ってSVMで推論

## 主張の有効性の検証方法
  - データセット：Infra-ADL2018
    - 7つの行動：
      - fall, sit still, stand still, sit to stand, stand to sit, walking from left to right, and walking from right to left.
  - 3つのセンサー，被験者8人，各行動10回
  - データセットの目的
  - 通常生活の人間の行動を認識するための低解像度赤外線センサの可用性のテスト
  - プライバシー保護しつつ，ヘルスケアのためにてい低解像度赤外線センサが使えるか試行
  - 提案手法が（特に転倒検知で）高い認識精度をとれることを示すためのデータセット
  - ベースラインのアルゴリズムと比較して，7つの行動のうち３つで大幅に良くなった．
  - ベースラインのアルゴリズムの論文としては以下
    - Use of low-resolution infrared pixel array for passive human motion movement and recognition

## 批評
  - データ数少なくない？
  - てか，データセット公開してなくない？
  - 読んでる俺らどうしようもなくない？検証しようがなくない？
  - 特徴抽出手法の妥当性の議論は？
  - オクルージョンどうするの？
  - うーん，やってみた感が…

## 次に読むべき論文
 (分野について読み始め)
  - 3D Convolutional Neural network for Home Monitoring using Low Resolution Thermal-sensor Array
    - 同じ著者
    - 手法をCNNにしましたって論文かな？

---
# A Spatio-Temporal Deep Learning Approach For Human Action Recognition in Infrared Videos

## 論文について (掲載ジャーナルなど)
- Anuj K Shah, Ripul Ghosh, Aparna Akula
- Proc. of SPIE Vol. 10751

## 概要
- 屋内環境での人間の行動認識は，事故や損傷を回避する上で超重要
  - 対象のアプリケーションドメイン
    - 独居高齢者，障害を持つ人の行動の監視
    - 単独で孤立した工場で働く人の監視
  - 赤外線センサの動画像の空間的時間的特徴を学習する3D-CNNを構築
  - 3D-CNN
    - (2つの畳み込み層＋1つのmax pool層)x2の6層
    - end-to-end？
  - 894のテストビデオのうち85%の分類精度

## 問題設定と解決したこと
- 身体装着型センサーは嫌われる→画像で→照明の問題とかプライバシーやばくね？→デプス画像やシルエットの検知で
  - このコンテクストだとKinectがよく使われてるやでー
  - でも暗いと無理→なら熱画像ならいけんじゃね？
- フォーカスを当てているのは（独居老人とか障害者の）転倒シーンの検出
  - 屋内と屋外でOK
- 近年画像＋CNNが上手くいってる→熱画像でもやられた
- 行動認識のために空間情報＋時間情報が良さそう

## 何をどう使ったのか
- IRカメラ：[FLIR E60 thermal infrared  camera https://www.ivytools.com/FLIR-E60-Infrared-Thermal-Imaging-Camera-p/flir-e60.htm]
  - Spectral range 7.5 to 13 µm
  - 320 x 240 pixel resolution, Frame Rate - 60 fps,
 - Athermalized manual focus lens, focal length 18 mm
- 3D-CNNで推測
 - 入力→conv-32(ReLU)→conv-32(ReLU)→maxpool(dropout)→conv-64(ReLU)→conv-64(ReLU)→maxpool(dropout)→FC-512(ReLU, dropout)→FC-8→softmax
 - 出力層以外でバッチノーマライゼーション
 - バッチサイズは32
 - 最適化手法はADAM
 - 損失関数はカテゴリカルクロスエントロピー

## 主張の有効性の検証方法
- 自作データセットで検証
- データセットの構成
  - 8つの行動を対象
  - 歩く，立つ，転倒，横たわる，座る，椅子から転倒，転倒から座る姿勢へ，転倒から立ち上がる
- 3つの環境で撮影
   - 学生室，寝室，庭
  - 被験者50人以上
  - データ詳細
    - 訓練用2641つのビデオ
    - テスト用894つのビデオ
    - 各ビデオ0.5秒
    - FLIRは30FPSで撮影したから15フレーム
- テストデータで検証，各行動のクラスの平均F1-Scoreが0.85

## 批評
- 他の転倒検知手法との比較は？
- ドロップアウトとバッチ正規化抜いたネットワークと比較しただけ？
- テストデータでは上手くいってますよーってだけ？
- うーん，熱画像＋3D-CNNをやってみた！感が…

---

# Action recognition from low-resolution infrared sensor for indoor use: a comparative study between deep learning and classical approaches

## 論文について (掲載ジャーナルなど)
 - Félix Polla ; Hélène Laurent ; Bruno Emile
 - 2019 20th IEEE International Conference on Mobile Data Management (MDM)

## 概要
- 低解像度センサーを用いた屋内環境での行動分析
  - 撮影された人がビデオで特定できないことを保証しながら行動認識を実行できるようにするため
- 既存のカメラによる行動認識では被験者の位置が限定される問題があるよね
- じゃあ，天井に赤外線センサーとりつければよくね？
- CoCAPSプロジェクトというのを企業とやってる
  - そこでシナリオとしてオフィス環境と7つの行動を対象とすることを決めた
  - 後の段階でいろんなセンサーの情報をマージして，人間の行動を特徴付ける
  - このフレームワークの中で低解像度赤外線センサー作ったんだと
- 提案手法：セグメント化された形状の重心位置の追跡から統計属性に基づく特徴＋分類にはMLP
- F値83%で認識

## 問題設定と解決したこと
- 64x64ピクセルの赤外線センサーを天井に設置
- オフィス環境
- 7つの行動を対象
  - アクションなし，落ち着きなく動く，地面に座る，立つ，椅子に座る，ゆっくり歩く(～1m/s)，早く歩く
  - 落ち着きのないアクションの内訳：電話への応答，オブジェクトの移動，パソコンの操作など
  - オフィスでよくやる動き
- データセットは700サンプル（各アクション100サンプル）

## 何をどう使ったのか
- ガウシアンフィルタをかけて平滑化＋閾値処理で明るい領域（現在フレームの人領域）と暗い領域（もともと人がいた場所の領域）を見つける
- 特徴量を計算（6つ）
  - 人の領域（楕円領域）の重心の軌跡（重心の動きのベクトル）
  - 軌跡ベクトルの統計特性（平均，最小，最大，標準偏差）
  - ビデオのアクティビティ＝　sum（セグメント化された人領域の面積 * 各フレームの重心の移動距離）
- 12の属性（明るい領域と暗い領域の２つ＊6つの特徴）をMLPにいれて分類

## 主張の有効性の検証方法
- ディープラーニングの手法と比較して，実装簡単だし計算リソースが少ない
  - リアルタイムのアプリケーションにいいだろうと主張
- 古典的手法と2つとディープラーニング手法3つ(3D-CNN, LSTM, 3D-CNN+LSTM)と比較
- 3D-CNNのF値85%で提案手法の方法F値83%だから悪くなくね？と主張

## 批評
- データ公開してくれー
- 1サンプルの長さは？
- なんで人がいた領域が暗くなるんだ？センサの特性？
- 明るい領域と暗い領域の特徴を計算しているけど，それただ単に前のフレームの人領域計算すればよくね？

## 次に読むべき論文
 [Computer Vision-Based Descriptive Analytics of Seniors’ Daily Activities for Long-Term Health Monitoring]
  Zelun Luo et al.

## 関連研究
- HOG特徴量+AdaBoostで行動認識
  - 多数のRGBカメラで撮影だったし，研究室環境にアドホックにルールを作っていったって感じ…あんまり
- 熱画像はノイズが多いからオプティカルフローとか勾配に基づく検出方法だと難しいとのこと
- 既存の行動ごとの身体シルエット作って二次元配列走査
  - 身体の特定の部位（手，足，頭）を認識，組み合わせて動作を認識
  - 複数のカメラから3Dの動きをキャプチャして，スケルトン化

---

# Computer Vision-Based Descriptive Analytics of Seniors’ Daily Activities for Long-Term Health Monitoring

## 論文について (掲載ジャーナルなど)
-  Jun-Ting Hsieh*, Zelun Luo*, Niranjan Balachandar, Serena Yeung, Guido Pusiol, Jay Luxenberg, Grace Li, Li-Jia Li, N. Lance Downing, Arnold Milstein, Li Fei-Fei
-  Proceedings of Machine Learning Research 85:1–18, 2018

## 概要
- 高齢者増えてる→介護者が継続的に監視することは困難→高齢者を支援する介護者の能力向上が必要
- 高齢者の日常生活の行動のパターンを自動でセンシングできれば，高齢者の健康に関する手がかりになる
  - センシングにはウェアラブルセンサーが考えられる（侵入型）→邪魔，高齢者つけてくれない
  -  非侵入型→コンピュータビジョンベースのアプローチ
  -  プライバシー保護→デプス＋熱画像
- 高齢者の日常活動パターンの定性的＆定量的な認識を実現

## 問題設定と解決したこと
- ウェアラブルセンサーNG→ 固定カメラ，センサーに基づくビジョンベースのアプローチ
- 既存のアプローチは転倒検知にフォーカス→通常の行動の認識も（高齢者のヘルスケアというコンテクストでは）大事だよね
- 現実の高齢者のデータを使おう
- RGBカメラはプライバシーを考えるとNG→デプス＋熱画像でやろう
  - データ構成
    - デプス＋熱画像
    - タイムスタンプで両者をマッチング
  - ７つのアクティビティ（6つの行動＋背景）
    -  ベッドに座っている，立っている，歩いている，寝ている，介護を受けている，ベッドサイドの便器を使っている，背景
  - アクティビティの識別用に訓練用7日間，テスト用3日間のデータを収集＋アノテーション
  - 長期分析用に14日間撮影
- 連続したマルチモーダルビデオが与えられた場合に、長期間にわたってアクティビティのタイムラインを予測
  - ビデオを異なるセグメントに分割→それぞれが一つのアクティビティに対応

## 何をどう使ったのか
-  深度センサ
  -  ASUS Xtion PRO depth sensor
  -  240x320, 30fps
-  熱センサ
  -  FLIR Lepton 3 thermal sensor
  -  160x120, 8.8fps
-  短いビデオクリップを学習し，7つのアクティビティをリアルタイムで分類
-  スライドウィンドウ方式で長期のビデオに7つのアクティビティをタグ付けして，毎日のアクティビティタイムラインを構築
-  深度センサの情報＋熱センサの情報をResNet-34で分類
-  すべての入力を224x224にスケーリング&トレーニングセットの平均と標準偏差で正規化
-  ランダムな水平フリップでデータオーグメンテーション
-  ImageNetの事前トレーニング済みモデルで初期化
  -  RGBイメージでトレーニングされててチャンネル数が異なる→RGBチャンネル全体の重みの平均をとる
-  最適化手法：SGD（40エポック）
  - バッチサイズ：8
  - momentum：0.9
  - 重みの減衰率：[$ 5* 10^{-4} ]
  - 学習率：0.001
  - 20エポックと30エポックで学習率を[$ \frac{1}{10}]
-  ビデオクリップの長さT：10
-  スムージングウィンドウW：5
- Late fusion: 深度画像で学習＋熱画像で学習→それぞれの結果の平均をとって統合

## 主張の有効性の検証方法
- アクティビティの識別の検証
- 7つのアクティビティを識別できるかで検証
- 各アクティビティのデータセットが偏っている（寝ている状態と背景が多い←当たり前だが）
  - →各カテゴリの平均精度AP（precision-recall曲線の下の面積）をカテゴリごとに平均したmAPでパフォーマンスを評価
- 訓練用7日間，テスト用3日間で検証
- ”歩く”のカテゴリを除いた各カテゴリでmAPが0.9超えてるからいいんじゃね？
- 長期的なアクティビティのタイムラインのが構築できるか検証
  - 14日間の各日の睡眠時間のグラフや，各アクティビティが起こったタイムラインのヒートマップを作成できることを確認

## 批評
 >an automated, non-intrusive, privacy-compliant vision-based system trained on real video data for continuous senior activity detection and long-term health monitoring has not been developed prior to our work.

- ↑まぁ，ここまで限定したコンテクストでは既存の研究はないやろな
- オクルージョンは？
- 一人だけが画像に写っていることが前提になっていて，活かしにくそう
  - 独居高齢者の見守りだからべつに「一人だけが写っている」という条件は問題ないのか…
- 式の文字の説明が離れすぎ！！！
- 読ませる気がないだろ
- $$
  x_i \in \mathbb{R}^{T \times H \times W \times C}
  $$
  - ↑これでTとHとWが何かわからんとか何を読み取れと言うんや
- 誤分類時の対処は？
  - ↑アプリケーションの話になるかなー
- 睡眠時間とか一日のタイムラインが出せることはわかったけど，その効果のほどはどう評価したらいいんだろうね

---
# Action Recognition from Extremely Low-Resolution Thermal Image Sequence

## 論文について (掲載ジャーナルなど)
- Takayuki Kawashima ; Yasutomo Kawanishi ; Ichiro Ide ; Hiroshi Murase ; Daisuke Deguchi et al.
- 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)

## 概要
- 独居高齢者の数が増加→介護者足らない→高齢者の身体機能の低下を[[自動で]]見つけたらいいね
- 高齢者の[[日常生活]]の行動センシングできたらいいね
  - テンポラリーだと体調とかに依るかもしれないしね
- 低解像度な赤外線センサでやってみるか
- 赤外線センサいいよね
  - 安価
  - 照明いらないから昼夜を問わない
  - （低解像度なら個人特定できないから）プライバシー守れる

## 問題設定と解決したこと
- 天井に赤外線センサつけて，下記行動を認識したいね
  - 日常行動（歩行，着席，起立）
  - 異常行動（転倒）
- 独居世帯を想定，センサの観測範囲内に入るのは[* 一人]だけと仮定
  - CNNとRNNを組み合わせたネットワークを使って人物行動認識
  - 前処理で種々の問題の解決を図る
- 動きの特徴だとオプティカルフローとか考えられるけどノイズまみれだから使えない問題
  - →ネットワークにフレーム間差分画像を入れる
- 天井から撮影された画像をそのまま特徴抽出に使うと，人物の動きではなく家具配置や人物の位置を学習し，学習データに含まれていない位置で起こる行動を認識できない問題（可能性）
  - →ネットワークに人物領域を切り出した画像を入れよう

## 何をどう使ったのか
- Thermal sensor D6T-1616L by OMRON
  - フレームレート10fps
  - 床面から220cmの高さに鉛直下向きに設置
  - 空調温度19℃に設定
- 前処理
  - 撮影した熱画像をGMMによる背景差分→前景を2値化→重心求める→重心から10画素四方の画像を元画像から切り出し→切り出された人体領域とする
  - 各画像[[系列]]における画素値の最大，最小値で各画像を正規化→フレーム間差分→フレーム間差分とった画像も上記位置で切り出し
- 人物行動認識
  - Recallが低くなるのが問題と考え2段階に分けて行動認識を行う
    - 行動検出
      - 行動尤度推定
        - ある時刻で，認識対象の行動が起きているか否かを識別
        - 「認識対象の行動」クラスと「その他」クラスの2クラス分類問題
    - 行動検出
      - 行動尤度を用いて行動検出，検出にはTAG（Temporal Actionness Grouping)を用いる
      - 複数の閾値を設定して，区間の重なりを許した複数の区間を検出
    - 行動分類
      - 検出されたすべての区間に対して行動分類を行う
        - 歩行，着席，起立，転倒の他「認識対象以外の行動」と「その他」（何も行動が起こっていない）に分類
- 後処理
  - 行動分類で出力された行動尤度をもとにNMS(Non-Maximum Suppression)を適用
  - 重複して検出された区間を最終的な行動認識結果として出力しないようにする
  - 最も尤度が高いクラスのみを出力
  - 「認識対象以外の行動」と「その他」の区間は出力しない
- ネットワーク構造
  - input(10x10x2)→conv-3x3(stride:1)→ReLU→maxpooling2x2(stride:2)→ReLU→conv-3x3(stride:1)→ReLU→maxpooling2x2(stride:2)→ReLU→conv-3x3(stride:1)→ReLU→FC→ReLU→FC→ReLU→BLSTM→Sigmoid→Softmax→output(classes)
  - 最適化手法：ADAM
  - FCに対してDropout 0.2
  - 損失関数：交差エントロピー
  - 画像をx，ｙ軸方向に±1ずらしてデータオーグメンテーション
  - 600エポック
- 各系列データに対して行動開始フレームと行動終了フレームをアノテーション
  - 被験者9人
    - 歩行，着席，起立，転倒を40本ずつ計1440本
    - 静止(立位，座位，臥位それぞれ40本）120本ずつ計1080本

## 主張の有効性の検証方法
- 着席，起立，転倒を認識対象の行動として，4分割交差検証で評価
- 比較手法と比べて提案手法が高いmAPを示した

## 批評
-  前処理の効果はいかほどなのであるか？

---
